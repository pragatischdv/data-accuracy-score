{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzY4KP/WP37QiTnPfG9pvo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nflows"
      ],
      "metadata": {
        "id": "V5ci3oWEs-Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m709gYVSaNWc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/pragatischdv/data-accuracy-score.git\n",
        "%cd data-accuracy-score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.decomposition import PCA\n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions.normal import StandardNormal\n",
        "from nflows.transforms.base import CompositeTransform\n",
        "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
        "from nflows.transforms.coupling import AffineCouplingTransform\n",
        "from nflows.transforms.linear import NaiveLinear\n",
        "from nflows.transforms.permutations import ReversePermutation\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from das import evaluate_das"
      ],
      "metadata": {
        "id": "AVT58U_2smK3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "# The target is already numeric, but let's simulate label encoding from names\n",
        "species_names = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "le = LabelEncoder()\n",
        "df[\"species\"] = le.fit_transform(species_names)\n",
        "\n",
        "print(df.head())\n",
        "print(\"\\nLabel mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTKjAl3va7Vd",
        "outputId": "27308eca-cf82-40fa-849a-d0a420b90de4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   species  \n",
            "0        0  \n",
            "1        0  \n",
            "2        0  \n",
            "3        0  \n",
            "4        0  \n",
            "\n",
            "Label mapping: {'setosa': np.int64(0), 'versicolor': np.int64(1), 'virginica': np.int64(2)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = df.drop(\"species\", axis=1)\n",
        "output_data = np.array(df[\"species\"])"
      ],
      "metadata": {
        "id": "5g6T5UYUseCj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CLASS_INT = 2\n",
        "MIN_CLASS_INT = 0\n",
        "N_SAMPLES = len(df)"
      ],
      "metadata": {
        "id": "SJNS4adYsueI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 1)\n",
        "input_data = pca.fit_transform(input_data)"
      ],
      "metadata": {
        "id": "B4PKmJ_3szfz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = []\n",
        "for i in range(len(output_data)):\n",
        "  final_data.append([input_data[i][0], output_data[i]])\n",
        "\n",
        "final_data = np.array(final_data)"
      ],
      "metadata": {
        "id": "y78IJcOFtJk9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 7\n",
        "base_dist = StandardNormal(shape=[2])\n",
        "num_iter = 1000"
      ],
      "metadata": {
        "id": "fWE5rSIttL88"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = []\n",
        "for _ in range(num_layers):\n",
        "     transforms.append(MaskedAffineAutoregressiveTransform(features=2,\n",
        "                                                            hidden_features=4))\n",
        "\n",
        "transform = CompositeTransform(transforms)\n",
        "\n",
        "flow = Flow(transform, base_dist)\n",
        "optimizer = optim.Adam(flow.parameters())"
      ],
      "metadata": {
        "id": "ViUfV_r1tPgt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    loss = -flow.log_prob(inputs=x).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "oH0MeO8ctSM8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = flow.sample(N_SAMPLES)\n",
        "samples = samples.detach().numpy()\n",
        "\n",
        "y_sample = samples[:, 1]\n",
        "for i in range(N_SAMPLES):\n",
        "  y_sample[i] = math.floor(y_sample[i])\n",
        "  if y_sample[i] < MIN_CLASS_INT:\n",
        "    y_sample[i] = MIN_CLASS_INT\n",
        "  elif y_sample[i] > MAX_CLASS_INT:\n",
        "    y_sample[i] = MAX_CLASS_INT"
      ],
      "metadata": {
        "id": "WyicwHwgtT0r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_cls = evaluate_das(\n",
        "    final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1),\n",
        "    samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1),\n",
        "    final_data[:, 0].reshape(-1, 1),  None,\n",
        "    task=\"classification\",\n",
        "    estimator=GaussianNB()\n",
        ")\n",
        "print(\"CLASSIFICATION RESULT:\", res_cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABNP0KB4tgOb",
        "outputId": "4ea3a66e-e9df-4c0e-9764-2cff22d807bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASSIFICATION RESULT: {'task': 'classification', 'estimator': 'GaussianNB', 'das': 61.33333333333333}\n"
          ]
        }
      ]
    }
  ]
}